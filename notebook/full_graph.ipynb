{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyprojroot import here\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "VECTORDB_DIR = \"data\\document_vectordb\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def lookup_documnet(query: str)->str:\n",
    "    \"\"\"Search within the given document to check whether certain options are permitted. Input should be a search query.\"\"\"\n",
    "    vectordb = Chroma(\n",
    "        collection_name=\"rag-chroma\",\n",
    "        persist_directory=str(here(VECTORDB_DIR)),\n",
    "        embedding_function=OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "    )\n",
    "    \n",
    "    docs = vectordb.similarity_search(query, k=2)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup_documnet\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "Search within the given document to check whether certain options are permitted. Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "print(lookup_documnet.name)\n",
    "print(lookup_documnet.args)\n",
    "print(lookup_documnet.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Amarok the lone wolf \\nIn the shadowed embrace of the Alaskan mountains, where the snow blankets the earth in a pristine \\nwhite and the northern lights dance across the sky like ethereal spirits, there lived a lone wolf named \\nAmarok. His coat was a tapestry of silver and midnight, a reflection of the landscape he called home. \\nAmarok was a creature of solitude, but his heart ached with the memory of the family he had lost to the \\nunforgiving wilderness. \\nAmarok's journey began on a day when the sky wept snowflakes as large as feathers, and the wind \\nwhispered secrets only the mountains could understand. He had been separated from his pack during a \\nfierce winter storm that had descended upon them like a ravenous beast. The pack had been everything \\nto Amarok: his community, his support, his family. Now, he roamed the vast expanse of the Alaskan \\nrange, driven by a deep longing to find them. \\nEach day was a testament to his resilience. Amarok traversed steep cliffs that clawed at the sky, crossed \\nfrozen rivers that mirrored the heavens, and navigated dense forests that stood as silent sentinels. His \\nkeen senses were his guide; his howl, a song of both sorrow and hope, echoed through the valleys, a call \\nto the family he yearned to see once more. \\nAs the seasons turned, Amarok's search led him to the heart of the mountains, where the air was thin \\nand the stars seemed close enough to touch. It was here, in the realm of the eagles, that Amarok found \\na clue. A familiar scent carried on the breeze, a scent that quickened his pulse and filled his being with a \\nmixture of excitement and trepidation. It was the unmistakable scent of his pack. \\nWith renewed vigor, Amarok followed the trail, his paws barely touching the snow as he raced against \\ntime. The scent grew stronger, guiding him over a ridge that revealed a valley cradled by the mountains. \\nAnd there, in the distance, he saw them: his family, alive and thriving. They were playing, their bodies a\\n\\nmixture of excitement and trepidation. It was the unmistakable scent of his pack. \\nWith renewed vigor, Amarok followed the trail, his paws barely touching the snow as he raced against \\ntime. The scent grew stronger, guiding him over a ridge that revealed a valley cradled by the mountains. \\nAnd there, in the distance, he saw them: his family, alive and thriving. They were playing, their bodies a \\nblur of motion against the stark landscape, their joyful yips reaching Amarok's ears like a melody long \\nforgotten. \\nAmarok approached cautiously, his heart pounding with a mixture of joy and uncertainty. Would they \\nremember him? Would they accept him back into the fold? As he neared, the pack caught sight of him. \\nFor a moment, time stood still, the only movement the gentle fall of snowflakes between them. \\nThen, recognition sparked in their eyes, and one by one, they came forward. Nuzzles and licks were \\nexchanged, each touch a word in the silent language of wolves. Amarok was home. The pack was whole \\nonce more, and together, they raised their voices to the sky, a chorus of unity and belonging that \\nresonated through the mountains of Alaska. \\nAmarok, the lone wolf who had braved the wilderness in search of his family, had found more than he \\nhad ever hoped for. He had found his way back to love, to connection, to the place where his spirit ran \\nfree. And there, amidst the peaks that touched the heavens, he knew he would never be alone again.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_documnet.invoke(\"can you describe me what is Amarok the lone wolf in 30 words?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "search_tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48',\n",
       "  'content': \"Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 | by Kamal Dhungana | Medium Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 LangGraph — State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI's innovations,Sharing insights for AI community growth Follow\"},\n",
       " {'url': 'https://blog.langchain.dev/langgraph/',\n",
       "  'content': 'TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\"tools\", \"model\") The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"What's a 'node' in LangGraph?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "print(search_tool.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "class SQLAgentTool:\n",
    "    \"\"\"\n",
    "    A tool for interacting with a travel-related SQL database using an LLM (Language Model) to generate and execute SQL queries.\n",
    "\n",
    "    This tool enables users to ask travel-related questions, which are transformed into SQL queries by a language model.\n",
    "    The SQL queries are executed on the provided SQLite database, and the results are processed by the language model to\n",
    "    generate a final answer for the user.\n",
    "\n",
    "    Attributes:\n",
    "        sql_agent_llm (ChatOpenAI): An instance of a ChatOpenAI language model used to generate and process SQL queries.\n",
    "        system_role (str): A system prompt template that guides the language model in answering user questions based on SQL query results.\n",
    "        db (SQLDatabase): An instance of the SQL database used to execute queries.\n",
    "        chain (RunnablePassthrough): A chain of operations that creates SQL queries, executes them, and generates a response.\n",
    "\n",
    "    Methods:\n",
    "        __init__: Initializes the TravelSQLAgentTool by setting up the language model, SQL database, and query-answering pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm: str, sqldb_directory: str, llm_temerature: float) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the TravelSQLAgentTool with the necessary configurations.\n",
    "\n",
    "        Args:\n",
    "            llm (str): The name of the language model to be used for generating and interpreting SQL queries.\n",
    "            sqldb_directory (str): The directory path where the SQLite database is stored.\n",
    "            llm_temerature (float): The temperature setting for the language model, controlling response randomness.\n",
    "        \"\"\"\n",
    "        self.sql_agent_llm = ChatOpenAI(\n",
    "            model=llm, temperature=llm_temerature)\n",
    "        # self.system_role = \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\n",
    "        #     Question: {question}\\n\n",
    "        #     SQL Query: {query}\\n\n",
    "        #     SQL Result: {result}\\n\n",
    "        #     Answer:\n",
    "        #     \"\"\"\n",
    "        self.db = SQLDatabase.from_uri(f\"sqlite:///{sqldb_directory}\")\n",
    "        print(self.db.get_usable_table_names())\n",
    "\n",
    "        print(\"table name printed\")\n",
    "\n",
    "        self.chain=create_sql_agent(llm=self.sql_agent_llm , db=self.db ,agent_executor_kwargs={\n",
    "            \"handle_parsing_errors\": True\n",
    "        })\n",
    "\n",
    "        # execute_query = QuerySQLDataBaseTool(db=self.db)\n",
    "        # write_query = create_sql_query_chain(\n",
    "        #     self.sql_agent_llm, self.db)\n",
    "        # answer_prompt = PromptTemplate.from_template(\n",
    "        #     self.system_role)\n",
    "\n",
    "        # answer = answer_prompt | self.sql_agent_llm | StrOutputParser()\n",
    "        # self.chain = (\n",
    "        #     RunnablePassthrough.assign(query=write_query).assign(\n",
    "        #         result=itemgetter(\"query\") | execute_query\n",
    "        #     )\n",
    "        #     | answer\n",
    "        # )\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "llm_model=\"gpt-4o-mini\"\n",
    "sqldb_directory_path=\"BIRD (1).db\"\n",
    "llm_temerature_arg=0.0\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_sqldb(query: str) -> str:\n",
    "    \"\"\"Query SQL Database and access all the information. Input should be a search query.\"\"\"\n",
    "    agent = SQLAgentTool(\n",
    "        llm=\"gpt-4o-mini\",\n",
    "        sqldb_directory=\"BIRD (1).db\",\n",
    "        llm_temerature=0.2\n",
    "    )\n",
    "    # response = agent.chain.run({\"question\": query})\n",
    "    response = agent.chain.run(query)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "Query SQL Database and access all the information. Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "print(query_sqldb.args)\n",
    "print(query_sqldb.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[search_tool,lookup_documnet,query_sqldb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model=\"gpt-4o-mini\" ,temperature=0.5)\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]\n",
    "\n",
    "graph_builder=StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c571b94d50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\",chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input={\"messages\":[llm_with_tools.invoke(\"What's a 'node' in LangGraph?\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'function': {'arguments': '{\"query\":\"node in LangGraph\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 155, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ccdd8d33-cd4e-4da0-ad42-8ef71b5f5b1b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'node in LangGraph'}, 'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 155, 'output_tokens': 22, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'function': {'arguments': '{\"query\":\"node in LangGraph\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 155, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-ccdd8d33-cd4e-4da0-ad42-8ef71b5f5b1b-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'node in LangGraph'}, 'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 155, 'output_tokens': 22, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'node in LangGraph'}, 'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'type': 'tool_call'}\n",
      "tavily_search_results_json\n",
      "{'query': 'node in LangGraph'}\n",
      "{'tavily_search_results_json': TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))), 'lookup_documnet': StructuredTool(name='lookup_documnet', description='Search within the given document to check whether certain options are permitted. Input should be a search query.', args_schema=<class 'langchain_core.utils.pydantic.lookup_documnet'>, func=<function lookup_documnet at 0x000001C5716C8220>), 'query_sqldb': StructuredTool(name='query_sqldb', description='Query SQL Database and access all the information. Input should be a search query.', args_schema=<class 'langchain_core.utils.pydantic.query_sqldb'>, func=<function query_sqldb at 0x000001C571BCC040>)}\n",
      "[{'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48', 'content': \"Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 | by Kamal Dhungana | Medium Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 LangGraph — State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI's innovations,Sharing insights for AI community growth Follow\"}, {'url': 'https://blog.langchain.dev/langgraph/', 'content': 'TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\"tools\", \"model\") The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)'}]\n",
      "[{'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48', 'content': \"Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 | by Kamal Dhungana | Medium Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 LangGraph — State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI's innovations,Sharing insights for AI community growth Follow\"}, {'url': 'https://blog.langchain.dev/langgraph/', 'content': 'TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\"tools\", \"model\") The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)'}]\n",
      "[{\"url\": \"https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48\", \"content\": \"Beginner\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\u2014 Part 1 | by Kamal Dhungana | Medium Beginner\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\u2014 Part 1 LangGraph \\u2014 State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI's innovations,Sharing insights for AI community growth Follow\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\\\"tools\\\", \\\"model\\\") The state of this graph by default contains concepts that should be familiar to you if you've used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)\"}]\n",
      "tavily_search_results_json\n",
      "call_y99x5O8EAX38KjivTzNt50O2\n",
      "[ToolMessage(content='[{\"url\": \"https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48\", \"content\": \"Beginner\\\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\\\u2014 Part 1 | by Kamal Dhungana | Medium Beginner\\\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\\\u2014 Part 1 LangGraph \\\\u2014 State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI\\'s innovations,Sharing insights for AI community growth Follow\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\\\\\"tools\\\\\", \\\\\"model\\\\\") The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)\"}]', name='tavily_search_results_json', tool_call_id='call_y99x5O8EAX38KjivTzNt50O2')]\n",
      "{'message': [ToolMessage(content='[{\"url\": \"https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48\", \"content\": \"Beginner\\\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\\\u2014 Part 1 | by Kamal Dhungana | Medium Beginner\\\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\\\u2014 Part 1 LangGraph \\\\u2014 State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI\\'s innovations,Sharing insights for AI community growth Follow\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\\\\\"tools\\\\\", \\\\\"model\\\\\") The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)\"}]', name='tavily_search_results_json', tool_call_id='call_y99x5O8EAX38KjivTzNt50O2')]}\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "msg=input.get(\"messages\",[])[-1]\n",
    "print(msg)\n",
    "tool_call=msg.tool_calls\n",
    "print(tool_call[-1])\n",
    "print(tool_call[-1][\"name\"])\n",
    "print(tool_call[-1][\"args\"])\n",
    "\n",
    "tools_by_name={tool.name:tool for tool in tools}\n",
    "print(tools_by_name)\n",
    "type(tools_by_name)\n",
    "\n",
    "tool_result=tools_by_name[tool_call[-1][\"name\"]].invoke(tool_call[-1][\"args\"])\n",
    "print(tool_result)\n",
    "\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "output=[]\n",
    "print(tool_result)\n",
    "print(json.dumps(tool_result))\n",
    "print(tool_call[-1][\"name\"])\n",
    "print(tool_call[-1][\"id\"])\n",
    "output.append(ToolMessage(\n",
    "    content=json.dumps(tool_result),\n",
    "    name=tool_call[-1][\"name\"],\n",
    "    tool_call_id=tool_call[-1][\"id\"],\n",
    "                )\n",
    ")\n",
    "print(output)\n",
    "print({\"message\":output})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c571b94d50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "# class BasicToolNode:\n",
    "#     \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "#     def __init__(self, tools: list) -> None:\n",
    "#         self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "#     def __call__(self, inputs: dict):\n",
    "#         if messages := inputs.get(\"messages\", []):\n",
    "#             message = messages[-1]\n",
    "#         else:\n",
    "#             raise ValueError(\"No message found in input\")\n",
    "#         outputs = []\n",
    "#         for tool_call in message.tool_calls:\n",
    "#             tool_result = self.tools_by_name[tool_call[-1][\"name\"]].invoke(\n",
    "#                 tool_call[-1][\"args\"]\n",
    "#             )\n",
    "#             outputs.append(\n",
    "#                 ToolMessage(\n",
    "#                     content=json.dumps(tool_result),\n",
    "#                     name=tool_call[-1][\"name\"],\n",
    "#                     tool_call_id=tool_call[-1][\"id\"],\n",
    "#                 )\n",
    "#             )\n",
    "#         return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "# tool_node = BasicToolNode(tools=[search_tool,lookup_documnet,query_sqldb])\n",
    "# graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[search_tool,lookup_documnet,query_sqldb])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'function': {'arguments': '{\"query\":\"node in LangGraph\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 155, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-ccdd8d33-cd4e-4da0-ad42-8ef71b5f5b1b-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'node in LangGraph'}, 'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 155, 'output_tokens': 22, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "[{'name': 'tavily_search_results_json', 'args': {'query': 'node in LangGraph'}, 'id': 'call_y99x5O8EAX38KjivTzNt50O2', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "ai_message=input.get(\"messages\",[])[-1]\n",
    "print(ai_message)\n",
    "print(ai_message.tool_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c571b94d50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# memory = MemorySaver()\n",
    "# graph = graph_builder.compile(checkpointer=memory)\n",
    "graph=graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the node in langgraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_Rmy0S8KdTeCJDp2IU77G1M1i)\n",
      " Call ID: call_Rmy0S8KdTeCJDp2IU77G1M1i\n",
      "  Args:\n",
      "    query: node in langgraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48\", \"content\": \"Beginner\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\u2014 Part 1 | by Kamal Dhungana | Medium Beginner\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\u2014 Part 1 LangGraph \\u2014 State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI's innovations,Sharing insights for AI community growth Follow\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\\\"tools\\\", \\\"model\\\") The state of this graph by default contains concepts that should be familiar to you if you've used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "In LangGraph, a \"node\" represents a specific function or operation that processes the current state of the graph. Each node can perform computations, modify the state, or generate outputs based on the input it receives. LangGraph is built on top of LangChain and is designed to facilitate the creation of cyclical graphs, which are often needed for agent runtimes. \n",
      "\n",
      "Nodes update the state of the graph, returning operations to attributes of this state in the form of a key-value store. After adding nodes, edges can be added to create connections between them, forming a complete graph. This structure allows for complex interactions and processes within LangGraph-based agents. \n",
      "\n",
      "For more detailed information, you can refer to the articles on [Medium](https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48) and [LangChain Blog](https://blog.langchain.dev/langgraph/).\n"
     ]
    }
   ],
   "source": [
    "# user_input = \"what is the node in langgraph?\"\n",
    "\n",
    "# # The config is the **second positional argument** to stream() or invoke()!\n",
    "# events = graph.stream(\n",
    "#     {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    "# )\n",
    "# for event in events:\n",
    "#     event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "user_input = \"what is the node in langgraph?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the node in langgraph?', additional_kwargs={}, response_metadata={}, id='482c3d9d-d87f-48dd-99b8-6b3ae24c6b25'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Rmy0S8KdTeCJDp2IU77G1M1i', 'function': {'arguments': '{\"query\":\"node in langgraph\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 154, 'total_tokens': 176, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ef0d0ac1-aecb-4ea9-b7e6-a9fabcc6dc05-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'node in langgraph'}, 'id': 'call_Rmy0S8KdTeCJDp2IU77G1M1i', 'type': 'tool_call'}], usage_metadata={'input_tokens': 154, 'output_tokens': 22, 'total_tokens': 176, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='[{\"url\": \"https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48\", \"content\": \"Beginner\\\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\\\u2014 Part 1 | by Kamal Dhungana | Medium Beginner\\\\u2019s Guide to LangGraph: Understanding State, Nodes, and Edges \\\\u2014 Part 1 LangGraph \\\\u2014 State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI\\'s innovations,Sharing insights for AI community growth Follow\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(\\\\\"tools\\\\\", \\\\\"model\\\\\") The state of this graph by default contains concepts that should be familiar to you if you\\'ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)\"}]', name='tavily_search_results_json', id='66b9aab0-9948-4ffc-9eba-f93f46b56928', tool_call_id='call_Rmy0S8KdTeCJDp2IU77G1M1i'),\n",
       "  AIMessage(content='In LangGraph, a \"node\" represents a specific function or operation that processes the current state of the graph. Each node can perform computations, modify the state, or generate outputs based on the input it receives. LangGraph is built on top of LangChain and is designed to facilitate the creation of cyclical graphs, which are often needed for agent runtimes. \\n\\nNodes update the state of the graph, returning operations to attributes of this state in the form of a key-value store. After adding nodes, edges can be added to create connections between them, forming a complete graph. This structure allows for complex interactions and processes within LangGraph-based agents. \\n\\nFor more detailed information, you can refer to the articles on [Medium](https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48) and [LangChain Blog](https://blog.langchain.dev/langgraph/).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 199, 'prompt_tokens': 589, 'total_tokens': 788, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-005698f8-a837-435e-b410-226cb23bc1c9-0', usage_metadata={'input_tokens': 589, 'output_tokens': 199, 'total_tokens': 788, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "give me the employee name with the highest salary\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query_sqldb (call_UoX0OqmkOdZNgfWsps9CSPnj)\n",
      " Call ID: call_UoX0OqmkOdZNgfWsps9CSPnj\n",
      "  Args:\n",
      "    query: SELECT name FROM employees ORDER BY salary DESC LIMIT 1;\n",
      "['Billing', 'ChangeOrder', 'ComplianceIssue', 'Contract', 'CostCodes', 'Employee', 'Expense', 'Invoice', 'Projects', 'Revenue', 'SubContract', 'Task', 'Time_Tracking']\n",
      "table name printed\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query_sqldb\n",
      "\n",
      "\"The employee with the highest hourly rate is Ian Garcia.\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The employee with the highest salary is Ian Garcia.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"give me the employee name with the highest salary\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "can you describe me what is Amarok the lone wolf in 15 words?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Amarok, the lone wolf, is a mythical creature symbolizing strength, independence, and wilderness spirit.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"can you describe me what is Amarok the lone wolf in 15 words?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "give me the top 5 employee id with highest salary\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query_sqldb (call_BbxZJED35g9RtSXZz70d3enw)\n",
      " Call ID: call_BbxZJED35g9RtSXZz70d3enw\n",
      "  Args:\n",
      "    query: SELECT employee_id, salary FROM employees ORDER BY salary DESC LIMIT 5;\n",
      "['Billing', 'ChangeOrder', 'ComplianceIssue', 'Contract', 'CostCodes', 'Employee', 'Expense', 'Invoice', 'Projects', 'Revenue', 'SubContract', 'Task', 'Time_Tracking']\n",
      "table name printed\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query_sqldb\n",
      "\n",
      "\"The top 5 employees by hourly rate are: (19, 67.81), (105, 67.81), (141, 67.81), (182, 67.81), (20, 59.14).\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The top 5 employee IDs with the highest salaries are:\n",
      "\n",
      "1. Employee ID: 19, Salary: $67.81\n",
      "2. Employee ID: 105, Salary: $67.81\n",
      "3. Employee ID: 141, Salary: $67.81\n",
      "4. Employee ID: 182, Salary: $67.81\n",
      "5. Employee ID: 20, Salary: $59.14\n"
     ]
    }
   ],
   "source": [
    "user_input = \"give me the top 5 employee id with highest salary\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "\n",
    "event={'messages': [HumanMessage(content='what is the node in langgraph?', additional_kwargs={}, response_metadata={}, id='dc891d2b-e0ce-4c45-b09e-a212ad5b6281'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0rvB5c85K8RQBNVPm4iVWaQ7', 'function': {'arguments': '{\"query\":\"node in langgraph\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 154, 'total_tokens': 176, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f2af3daf-c6c8-4f41-9f26-b1fc727e5fe9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'node in langgraph'}, 'id': 'call_0rvB5c85K8RQBNVPm4iVWaQ7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 154, 'output_tokens': 22, 'total_tokens': 176, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is the node in langgraph?', additional_kwargs={}, response_metadata={}, id='1c4e28d1-54dc-4ec4-a70a-afa6fd5d0bb0'), HumanMessage(content='what is the node in langgraph?.', additional_kwargs={}, response_metadata={}, id='fa0d6f02-a065-460a-8700-7399f62bfb09'), HumanMessage(content='what is the node in langgraph?.', additional_kwargs={}, response_metadata={}, id='760a2e7d-8db3-490e-91bc-f33f42d3aa48')]}\n",
    "print(event)\n",
    "print(event[\"messages\"])\n",
    "print(event[\"messages\"][-1])\n",
    "print(event[\"messages\"][-1].pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='give me the top 5 employee id with highest salary', additional_kwargs={}, response_metadata={}, id='d2687f36-0f09-4b77-a815-de4505eb6c49'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cxBAtH6Dnt0A0jLNczyOq6Lb', 'function': {'arguments': '{\"query\":\"SELECT employee_id, salary FROM employees ORDER BY salary DESC LIMIT 5;\"}', 'name': 'query_sqldb'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 157, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-752a4194-ca55-4ce6-8c14-7b322451389d-0', tool_calls=[{'name': 'query_sqldb', 'args': {'query': 'SELECT employee_id, salary FROM employees ORDER BY salary DESC LIMIT 5;'}, 'id': 'call_cxBAtH6Dnt0A0jLNczyOq6Lb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 157, 'output_tokens': 30, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='\"Agent stopped due to iteration limit or time limit.\"', name='query_sqldb', id='5d0515a4-937b-496d-a149-f5934b2b1bf6', tool_call_id='call_cxBAtH6Dnt0A0jLNczyOq6Lb'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aU8etm6OUM24sDTVnKZITs2H', 'function': {'arguments': '{\"query\":\"SELECT employee_id, salary FROM employees ORDER BY salary DESC LIMIT 5\"}', 'name': 'query_sqldb'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 206, 'total_tokens': 235, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-087a2d2b-8277-46ec-8e85-a011db159b4f-0', tool_calls=[{'name': 'query_sqldb', 'args': {'query': 'SELECT employee_id, salary FROM employees ORDER BY salary DESC LIMIT 5'}, 'id': 'call_aU8etm6OUM24sDTVnKZITs2H', 'type': 'tool_call'}], usage_metadata={'input_tokens': 206, 'output_tokens': 29, 'total_tokens': 235, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='\"Agent stopped due to iteration limit or time limit.\"', name='query_sqldb', id='768aaf77-a57a-4acc-8c30-d66d6d810799', tool_call_id='call_aU8etm6OUM24sDTVnKZITs2H'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_03JXOdur4s3RI1Ozv4B842iL', 'function': {'arguments': '{\"query\":\"SELECT employee_id, salary FROM employees ORDER BY salary DESC\"}', 'name': 'query_sqldb'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 254, 'total_tokens': 280, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aff179e8-f31c-4cef-94e2-c277dae6e022-0', tool_calls=[{'name': 'query_sqldb', 'args': {'query': 'SELECT employee_id, salary FROM employees ORDER BY salary DESC'}, 'id': 'call_03JXOdur4s3RI1Ozv4B842iL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 26, 'total_tokens': 280, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='\"Agent stopped due to iteration limit or time limit.\"', name='query_sqldb', id='6883b235-b930-435c-a78b-ee05fba7bd5a', tool_call_id='call_03JXOdur4s3RI1Ozv4B842iL'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JdHRvHbExAlS9pe7nKB5HMei', 'function': {'arguments': '{\"query\":\"SELECT employee_id, salary FROM employees\"}', 'name': 'query_sqldb'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 299, 'total_tokens': 321, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f5570bc8-b20f-437a-a96a-e1933907dbd5-0', tool_calls=[{'name': 'query_sqldb', 'args': {'query': 'SELECT employee_id, salary FROM employees'}, 'id': 'call_JdHRvHbExAlS9pe7nKB5HMei', 'type': 'tool_call'}], usage_metadata={'input_tokens': 299, 'output_tokens': 22, 'total_tokens': 321, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='\"Agent stopped due to iteration limit or time limit.\"', name='query_sqldb', id='687c6860-103c-40df-a1e9-b618732d8960', tool_call_id='call_JdHRvHbExAlS9pe7nKB5HMei'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hatSE37ztCLWCOXnxMz7oDc5', 'function': {'arguments': '{\"query\":\"SELECT employee_id, salary FROM employees LIMIT 10\"}', 'name': 'query_sqldb'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 340, 'total_tokens': 365, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7fefaa22-2b9c-4363-ac82-f6e35cf82252-0', tool_calls=[{'name': 'query_sqldb', 'args': {'query': 'SELECT employee_id, salary FROM employees LIMIT 10'}, 'id': 'call_hatSE37ztCLWCOXnxMz7oDc5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 340, 'output_tokens': 25, 'total_tokens': 365, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='\"Agent stopped due to iteration limit or time limit.\"', name='query_sqldb', id='f16ee94c-4a8f-430c-9698-cc5ab4af9dc4', tool_call_id='call_hatSE37ztCLWCOXnxMz7oDc5'),\n",
       "  AIMessage(content=\"It seems that I'm unable to retrieve the employee data due to some limitations in querying the database. If you have access to the data or a specific dataset, you could provide it, and I can help you analyze it. Alternatively, if you have any other questions or need assistance with something else, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 384, 'total_tokens': 450, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-24aef598-a727-41cb-bd13-cd6a52f4e8e5-0', usage_metadata={'input_tokens': 384, 'output_tokens': 66, 'total_tokens': 450, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
